{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "DL4CV_4_ObjectDet.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_AdvCV_Experis2020/blob/main/day4/DL4CV_4_ObjectDet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYVNUiBLNMNP"
      },
      "source": [
        "# Introduction to Object Detection\r\n",
        "\r\n",
        "      This is an extra lecture on Obj Det. Material must be re-write for sharing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcviVNr_ch7d"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/real_time_object_detection.jpg\" width=\"500\">\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rzVKCR48QNM"
      },
      "source": [
        "   Email: m.alberti@deeplearningitalia.com\n",
        "\n",
        "   Linkedin:\n",
        "   [linkedin_matteo_alberti](www.linkedin.com/in/matteo-alberti-695570110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBLBwiI48QNM"
      },
      "source": [
        "# One step at a time : \r\n",
        "\r\n",
        "      Going Backwards!\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbjQ17ErQGQL"
      },
      "source": [
        "## Which will be the core family behind deep learning models?\r\n",
        "\r\n",
        "      We are working still with images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcWYFTTFOLQV"
      },
      "source": [
        "## How should we evaluate?\r\n",
        "\r\n",
        "*Evaluation Metrics: mAP*\r\n",
        "\r\n",
        "**mAP**, short for “mean average precision”.\r\n",
        "- Range : from 0 to 100\r\n",
        "- Higher value is better.\r\n",
        "\r\n",
        "*What is?*\r\n",
        "\r\n",
        "Combine all detections from all test images to draw a precision-recall curve (PR curve) for each class; The “average precision” (AP) is the area under the PR curve. (**Do you remember something?**)\r\n",
        "\r\n",
        "Given that target objects are in different classes, we first compute AP separately for each class, and then average over classes.\r\n",
        "A detection is a true positive if it has “intersection over union” (IoU) with a ground-truth box greater than some threshold (usually 0.5; if so, the metric is “mAP@0.5”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za4WVk63Qf8t"
      },
      "source": [
        "### If you think carefully we have quite all blocks needed!\r\n",
        "\r\n",
        "      Convolutions + new criterion\r\n",
        "\r\n",
        "      What else?\r\n",
        "      - New Data Structure\r\n",
        "      - New Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcyruL_M8QNM"
      },
      "source": [
        "## Introduction CNN for Obj Detection\n",
        "\n",
        "- <font color=BE3315>**R-CNN idea** </font> \n",
        "- <font color=C24024>**Variants like Fast, Faster and Mask** </font> \n",
        "- <font color=E15234>**SSD** </font> \n",
        "\n",
        "- <font color=E35F2A>**Exercises** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfERpSWN8QNM"
      },
      "source": [
        "## R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rv9DM10RiX3"
      },
      "source": [
        "R-CNN or “Region-based Convolutional Neural Networks”. \r\n",
        "\r\n",
        "Two steps :\r\n",
        "- using selective search and it identifies a manageable number of bounding-box object region candidates (“region of interest” or “**RoI**”).\r\n",
        "- And then it extracts CNN features from each region independently for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6vxCbGxSA6c"
      },
      "source": [
        "![](https://lilianweng.github.io/lil-log/assets/images/RCNN.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnXMlUpgUaHn"
      },
      "source": [
        "## WORKFLOW\r\n",
        "\r\n",
        "1) Pre-train a CNN network on image classification tasks. Like **VGG or ResNet**. *Pretrained models are welcome!* . The classification task involves N classes\r\n",
        "\r\n",
        "2) Propose category-independent regions of interest by **selective search**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l93iQjtjVZzw"
      },
      "source": [
        "-----------------------------------------------------------------\r\n",
        "\r\n",
        "*What is selective search??*\r\n",
        "\r\n",
        "<img src=\"https://lilianweng.github.io/lil-log/assets/images/selective-search-algorithm.png\" width=\"400\">\r\n",
        "\r\n",
        "*Main idea*\r\n",
        "\r\n",
        "- First the similarities between all neighbouring regions are calculated.\r\n",
        "- The two most similar regions are grouped together, and new similarities are calculated between the resulting region and its neighbours.\r\n",
        "\r\n",
        "-----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1G4Ake_SA9D"
      },
      "source": [
        "3) Region candidates are warped to have a fixed size as required by CNN. (**Why?**)\r\n",
        "\r\n",
        "4) Fine tuning on warped regions with number of classes + 1 (background)\r\n",
        "\r\n",
        "5) Given every image region, one forward propagation through the CNN generates a feature vector. This feature vector is then consumed by a **binary** SVM (can you say me why SVM??) trained for each class **independently**. \r\n",
        "\r\n",
        "- Proposed regions are the ones with IoU (intersection over union) higher than a given threshold\r\n",
        "\r\n",
        "6) To reduce the localization errors, a regression model is trained to correct the predicted detection window on bounding box correction offset using CNN features \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF9PyZelY-a1"
      },
      "source": [
        "*We will not define into details this step. If you're interested this is called Bounding Box Regression* **BUT** the main idea is the following :\r\n",
        "\r\n",
        "<img src=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-030-20876-9_24/MediaObjects/484523_1_En_24_Fig1_HTML.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrkWOe7FRicu"
      },
      "source": [
        "## Faster R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SotbbIDQRkM3"
      },
      "source": [
        "<img src=\"https://lilianweng.github.io/lil-log/assets/images/fast-RCNN.png\" width=\"500\">\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz-yqmbKRkPM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH4YDHz9RkR3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao7KP7BDRkU6"
      },
      "source": [
        "## Fastest R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq-oYcMbRmHl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpugdqQvRmJ-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5zxjAJ0RmM7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjWPFkvxRmPW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3OVTb8qRmSb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydTfDdcNRmUk"
      },
      "source": [
        "## Mask R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jwPHklBSHxM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRocOHsuRqL-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cet6a8UaRqPD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yzH70S1TutA"
      },
      "source": [
        "## SSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuxh902YTv_s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lusyE-l_TwCa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf2kIOU1TwFH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNuicxHUTwIi"
      },
      "source": [
        "## YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmT_8pn2TxzS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSayTH2WTx1m"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56NasrZqTx4W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0bdL6xHTx7f"
      },
      "source": [
        ""
      ]
    }
  ]
}